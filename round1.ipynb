{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            commercial_name  \\\n",
      "0               White Horse   \n",
      "1  Wealth Solution Partners   \n",
      "2                       PMG   \n",
      "3          TMP Capital PLLC   \n",
      "4            Genertek Power   \n",
      "\n",
      "                                       business_tags  \\\n",
      "0  Tile Manufacturing | European Aesthetics Ceram...   \n",
      "1  Super and SMSF Services | Financial Planning a...   \n",
      "2  Fire and Water Cleanup Services | Mold Remedia...   \n",
      "3  Licensed in AL & FL | 203K Loans | 15-year Fix...   \n",
      "4  Industrial and Commercial Energy Storage | Ass...   \n",
      "\n",
      "                                   short_description  \\\n",
      "0  White Horse is highly regarded as a tile trail...   \n",
      "1  WSP, Wealth Solution Partners, Financial Plann...   \n",
      "2  PMG General Solutions Inc. is an environmental...   \n",
      "3  TMP Capital PLLC Consulting Company Franklin M...   \n",
      "4  Genertek Power Ltd a UK electricity systems & ...   \n",
      "\n",
      "                                         description  \\\n",
      "0  White Horse Ceramic Singapore is a leading man...   \n",
      "1  Wealth Solution Partners Pty Ltd is an indepen...   \n",
      "2  PMG General Solutions Inc. is an environmental...   \n",
      "3  TMP Capital PLLC Consulting Company, also know...   \n",
      "4  Genertek Power Limited is a privately-owned UK...   \n",
      "\n",
      "                        main_business_category  \n",
      "0                                   Tile Store  \n",
      "1  Investment Consultants & Financial Advisors  \n",
      "2        Damage Restoration & Mold Remediation  \n",
      "3                             Mortgage Brokers  \n",
      "4                   Renewable energy companies  \n"
     ]
    }
   ],
   "source": [
    "path = r'C:\\Users\\wadu\\Desktop\\Veridion_hackathon\\tournament_hints_data.csv'\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# This will display the first few rows of the DataFrame\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorted by occurrences (ascending): [(2, 3), (3, 3146), (4, 6071), (5, 10537), (6, 17654), (7, 22360), (8, 29782), (9, 30909), (10, 30833), (11, 32583), (12, 35582), (13, 37725), (14, 38812), (15, 38818), (16, 36725), (17, 34907), (18, 31329), (19, 27866), (20, 25426), (21, 20524), (22, 18193), (23, 15948), (24, 13751), (25, 11813), (26, 9871), (27, 8164), (28, 6715), (29, 5534), (30, 4485), (31, 3452), (32, 2928), (33, 2360), (34, 1966), (35, 1570), (36, 1370), (37, 1084), (38, 914), (39, 770), (40, 579), (41, 478), (42, 407), (43, 355), (44, 286), (45, 260), (46, 228), (47, 184), (48, 147), (49, 139), (50, 103), (51, 93), (52, 89), (53, 58), (54, 68), (55, 48), (56, 37), (57, 42), (58, 29), (59, 21), (60, 29), (61, 22), (62, 18), (63, 17), (64, 19), (65, 7), (66, 1), (67, 1), (103, 1)]\n",
      "Sorted by occurrences (descending): [(103, 1), (67, 1), (66, 1), (65, 7), (64, 19), (63, 17), (62, 18), (61, 22), (60, 29), (59, 21), (58, 29), (57, 42), (56, 37), (55, 48), (54, 68), (53, 58), (52, 89), (51, 93), (50, 103), (49, 139), (48, 147), (47, 184), (46, 228), (45, 260), (44, 286), (43, 355), (42, 407), (41, 478), (40, 579), (39, 770), (38, 914), (37, 1084), (36, 1370), (35, 1570), (34, 1966), (33, 2360), (32, 2928), (31, 3452), (30, 4485), (29, 5534), (28, 6715), (27, 8164), (26, 9871), (25, 11813), (24, 13751), (23, 15948), (22, 18193), (21, 20524), (20, 25426), (19, 27866), (18, 31329), (17, 34907), (16, 36725), (15, 38818), (14, 38812), (13, 37725), (12, 35582), (11, 32583), (10, 30833), (9, 30909), (8, 29782), (7, 22360), (6, 17654), (5, 10537), (4, 6071), (3, 3146), (2, 3)]\n",
      "Ontario Student Trustees' Association l'Association des élèves conseillers et conseillères de l'Ontario\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame and you've loaded your CSV file into it\n",
    "first_column = df.iloc[:, 0]\n",
    "\n",
    "# Initialize an empty dictionary to store string lengths\n",
    "length_counts = {}\n",
    "\n",
    "# Iterate over each string in the first column\n",
    "for x in first_column:\n",
    "    # Calculate the length of the string\n",
    "    length = len(x)\n",
    "\n",
    "    # Update the dictionary with the string length count\n",
    "    if length in length_counts:\n",
    "        length_counts[length] += 1\n",
    "    else:\n",
    "        length_counts[length] = 1\n",
    "\n",
    "# Sort the dictionary by values in ascending order\n",
    "sorted_length_counts_asc = sorted(length_counts.items(), key=lambda x: x[0])\n",
    "\n",
    "# Sort the dictionary by values in descending order\n",
    "sorted_length_counts_desc = sorted(length_counts.items(), key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# Print the sorted results\n",
    "print(\"Sorted by occurrences (ascending):\", sorted_length_counts_asc)\n",
    "print(\"Sorted by occurrences (descending):\", sorted_length_counts_desc)\n",
    "\n",
    "for x in first_column:\n",
    "    if len(x) == 103:\n",
    "        print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        09   10  100  101  1010  102  103  106  108  10th  ...  zzenith  \\\n",
      "0      0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0   \n",
      "1      0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0   \n",
      "2      0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0   \n",
      "3      0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0   \n",
      "4      0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0   \n",
      "...    ...  ...  ...  ...   ...  ...  ...  ...  ...   ...  ...      ...   \n",
      "49995  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0   \n",
      "49996  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0   \n",
      "49997  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0   \n",
      "49998  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0   \n",
      "49999  0.0  0.0  0.0  0.0   0.0  0.0  0.0  0.0  0.0   0.0  ...      0.0   \n",
      "\n",
      "       zımba  التـجـاريـة  الدوليـة  سـادن  شـركـة  立普思股份有限公司  試劑公司  誠懇可信  \\\n",
      "0        0.0          0.0       0.0    0.0     0.0        0.0   0.0   0.0   \n",
      "1        0.0          0.0       0.0    0.0     0.0        0.0   0.0   0.0   \n",
      "2        0.0          0.0       0.0    0.0     0.0        0.0   0.0   0.0   \n",
      "3        0.0          0.0       0.0    0.0     0.0        0.0   0.0   0.0   \n",
      "4        0.0          0.0       0.0    0.0     0.0        0.0   0.0   0.0   \n",
      "...      ...          ...       ...    ...     ...        ...   ...   ...   \n",
      "49995    0.0          0.0       0.0    0.0     0.0        0.0   0.0   0.0   \n",
      "49996    0.0          0.0       0.0    0.0     0.0        0.0   0.0   0.0   \n",
      "49997    0.0          0.0       0.0    0.0     0.0        0.0   0.0   0.0   \n",
      "49998    0.0          0.0       0.0    0.0     0.0        0.0   0.0   0.0   \n",
      "49999    0.0          0.0       0.0    0.0     0.0        0.0   0.0   0.0   \n",
      "\n",
      "       防漏止水  \n",
      "0       0.0  \n",
      "1       0.0  \n",
      "2       0.0  \n",
      "3       0.0  \n",
      "4       0.0  \n",
      "...     ...  \n",
      "49995   0.0  \n",
      "49996   0.0  \n",
      "49997   0.0  \n",
      "49998   0.0  \n",
      "49999   0.0  \n",
      "\n",
      "[50000 rows x 34705 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming you have already loaded your DataFrame 'df'\n",
    "# Extract the first 100 entries of the first column\n",
    "first_column = df.iloc[:50000, 0]\n",
    "\n",
    "# Initialize the TF-IDF Vectorizer\n",
    "vectorizer_tfidf = TfidfVectorizer()\n",
    "\n",
    "# Fit and Transform the column data\n",
    "tfidf_matrix = vectorizer_tfidf.fit_transform(first_column)\n",
    "\n",
    "# Get the feature names (words) to use as DataFrame columns\n",
    "feature_names = vectorizer_tfidf.get_feature_names_out()\n",
    "\n",
    "# Create a DataFrame for better visibility of TF-IDF results\n",
    "df_tfidf = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "\n",
    "# Print the resulting DataFrame\n",
    "print(df_tfidf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       name  naics_code  \\\n",
      "0               White Horse       327.0   \n",
      "1  Wealth Solution Partners       523.0   \n",
      "2                       PMG       562.0   \n",
      "3          TMP Capital PLLC       522.0   \n",
      "4            Genertek Power       221.0   \n",
      "\n",
      "                                    naics_label  \n",
      "0                                           NaN  \n",
      "1                                           NaN  \n",
      "2                                           NaN  \n",
      "3  Credit Intermediation and Related Activities  \n",
      "4                                           NaN  \n"
     ]
    }
   ],
   "source": [
    "path_generate = r'C:\\Users\\wadu\\Desktop\\Veridion_hackathon\\cleaned_naics_codes.csv'\n",
    "df_generate = pd.read_csv(path_generate)\n",
    "print(df_generate.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{111: 0, 112: 1, 113: 2, 114: 3, 115: 4, 211: 5, 212: 6, 213: 7, 221: 8, 236: 9, 237: 10, 238: 11, 311: 12, 312: 13, 313: 14, 314: 15, 315: 16, 316: 17, 321: 18, 322: 19, 323: 20, 324: 21, 325: 22, 326: 23, 327: 24, 331: 25, 332: 26, 333: 27, 334: 28, 335: 29, 336: 30, 337: 31, 339: 32, 423: 33, 424: 34, 425: 35, 441: 36, 444: 37, 445: 38, 449: 39, 455: 40, 456: 41, 457: 42, 458: 43, 459: 44, 481: 45, 482: 46, 483: 47, 484: 48, 485: 49, 486: 50, 487: 51, 488: 52, 491: 53, 492: 54, 493: 55, 512: 56, 513: 57, 516: 58, 517: 59, 518: 60, 519: 61, 521: 62, 522: 63, 523: 64, 524: 65, 525: 66, 531: 67, 532: 68, 533: 69, 541: 70, 551: 71, 561: 72, 562: 73, 611: 74, 621: 75, 622: 76, 623: 77, 624: 78, 711: 79, 712: 80, 713: 81, 721: 82, 722: 83, 811: 84, 812: 85, 813: 86, 814: 87, 921: 88, 922: 89, 923: 90, 924: 91, 925: 92, 926: 93, 927: 94, 928: 95}\n"
     ]
    }
   ],
   "source": [
    "def mapping_labels(dataframe):\n",
    "\n",
    "  dictionary_labels = {}\n",
    "\n",
    "\n",
    "  for i in range(len(dataframe)):\n",
    "\n",
    "    naics_code = dataframe['naics_code'][i]\n",
    "\n",
    "    dictionary_labels[naics_code] = i\n",
    "\n",
    "  return dictionary_labels\n",
    "\n",
    "taxonomy = pd.read_csv(r\"C:\\Users\\wadu\\Desktop\\Veridion_hackathon\\Naics3(label)taxonomy.csv\")\n",
    "dictionar = mapping_labels(taxonomy)\n",
    "print(dictionar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'your_column_name' is the name of the column you want to check for NaN values\n",
    "df_generate = df_generate.dropna(subset=['naics_code'])\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "# First, add the mapped labels to the DataFrame\n",
    "df_generate['mapped_label'] = df_generate['naics_code'].map(dictionar)\n",
    "df_generate = df_generate.dropna(subset=['mapped_label'])\n",
    "\n",
    "\n",
    "# Split the DataFrame into features (X) and labels (y)\n",
    "X = df_generate['name']  # Assuming 'name' column contains company names which will be used as features\n",
    "y = df_generate['mapped_label']  # The new column with mapped labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m log_reg \u001b[38;5;241m=\u001b[39m LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m)  \u001b[38;5;66;03m# Increased max_iter in case the default isn't sufficient\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Train the Logistic Regression model using BoW features\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m \u001b[43mlog_reg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_bow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Predict on the test data using BoW features\u001b[39;00m\n\u001b[0;32m     38\u001b[0m y_pred_bow \u001b[38;5;241m=\u001b[39m log_reg\u001b[38;5;241m.\u001b[39mpredict(X_test_bow)\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1303\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1301\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1303\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1306\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1307\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1308\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1309\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1310\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1311\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1312\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1313\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1314\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1315\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1322\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1324\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1325\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1326\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1328\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:452\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    448\u001b[0m l2_reg_strength \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C\n\u001b[0;32m    449\u001b[0m iprint \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m101\u001b[39m][\n\u001b[0;32m    450\u001b[0m     np\u001b[38;5;241m.\u001b[39msearchsorted(np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]), verbose)\n\u001b[0;32m    451\u001b[0m ]\n\u001b[1;32m--> 452\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mw0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL-BFGS-B\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg_strength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43miprint\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43miprint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgtol\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    460\u001b[0m n_iter_i \u001b[38;5;241m=\u001b[39m _check_optimize_result(\n\u001b[0;32m    461\u001b[0m     solver,\n\u001b[0;32m    462\u001b[0m     opt_res,\n\u001b[0;32m    463\u001b[0m     max_iter,\n\u001b[0;32m    464\u001b[0m     extra_warning_msg\u001b[38;5;241m=\u001b[39m_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n\u001b[0;32m    465\u001b[0m )\n\u001b[0;32m    466\u001b[0m w0, loss \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx, opt_res\u001b[38;5;241m.\u001b[39mfun\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43m_minimize_lbfgsb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjac\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    711\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:365\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    359\u001b[0m task_str \u001b[38;5;241m=\u001b[39m task\u001b[38;5;241m.\u001b[39mtobytes()\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFG\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;66;03m# The minimization routine wants f and g at the current x.\u001b[39;00m\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;66;03m# Note that interruptions due to maxfun are postponed\u001b[39;00m\n\u001b[0;32m    363\u001b[0m     \u001b[38;5;66;03m# until the completion of the current minimization iteration.\u001b[39;00m\n\u001b[0;32m    364\u001b[0m     \u001b[38;5;66;03m# Overwrite f and g:\u001b[39;00m\n\u001b[1;32m--> 365\u001b[0m     f, g \u001b[38;5;241m=\u001b[39m \u001b[43mfunc_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m task_str\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNEW_X\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    367\u001b[0m     \u001b[38;5;66;03m# new iteration\u001b[39;00m\n\u001b[0;32m    368\u001b[0m     n_iterations \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:285\u001b[0m, in \u001b[0;36mScalarFunction.fun_and_grad\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray_equal(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx):\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_x_impl(x)\n\u001b[1;32m--> 285\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_grad()\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_fun_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m \u001b[43mfun_wrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:77\u001b[0m, in \u001b[0;36mMemoizeJac.__call__\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, \u001b[38;5;241m*\u001b[39margs):\n\u001b[0;32m     76\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" returns the function value \"\"\"\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_if_needed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:71\u001b[0m, in \u001b[0;36mMemoizeJac._compute_if_needed\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39mall(x \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m---> 71\u001b[0m     fg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjac \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value \u001b[38;5;241m=\u001b[39m fg[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:275\u001b[0m, in \u001b[0;36mLinearModelLoss.loss_gradient\u001b[1;34m(self, coef, X, y, sample_weight, l2_reg_strength, n_threads, raw_prediction)\u001b[0m\n\u001b[0;32m    272\u001b[0m n_dof \u001b[38;5;241m=\u001b[39m n_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_intercept)\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raw_prediction \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 275\u001b[0m     weights, intercept, raw_prediction \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight_intercept_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoef\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    277\u001b[0m     weights, intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_intercept(coef)\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\linear_model\\_linear_loss.py:166\u001b[0m, in \u001b[0;36mLinearModelLoss.weight_intercept_raw\u001b[1;34m(self, coef, X)\u001b[0m\n\u001b[0;32m    163\u001b[0m     raw_prediction \u001b[38;5;241m=\u001b[39m X \u001b[38;5;241m@\u001b[39m weights \u001b[38;5;241m+\u001b[39m intercept\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# weights has shape (n_classes, n_dof)\u001b[39;00m\n\u001b[1;32m--> 166\u001b[0m     raw_prediction \u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m \u001b[38;5;241m+\u001b[39m intercept  \u001b[38;5;66;03m# ndarray, likely C-contiguous\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m weights, intercept, raw_prediction\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\sparse\\_base.py:624\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    623\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 624\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_dispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\sparse\\_base.py:526\u001b[0m, in \u001b[0;36m_spbase._mul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_vector(other\u001b[38;5;241m.\u001b[39mravel())\u001b[38;5;241m.\u001b[39mreshape(M, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m N:\n\u001b[1;32m--> 526\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mul_multivector\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    528\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    529\u001b[0m     \u001b[38;5;66;03m# scalar value\u001b[39;00m\n\u001b[0;32m    530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mul_scalar(other)\n",
      "File \u001b[1;32mc:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:496\u001b[0m, in \u001b[0;36m_cs_matrix._mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    493\u001b[0m M, N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    494\u001b[0m n_vecs \u001b[38;5;241m=\u001b[39m other\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# number of column vectors\u001b[39;00m\n\u001b[1;32m--> 496\u001b[0m result \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((M, n_vecs),\n\u001b[0;32m    497\u001b[0m                   dtype\u001b[38;5;241m=\u001b[39mupcast_char(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar, other\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mchar))\n\u001b[0;32m    499\u001b[0m \u001b[38;5;66;03m# csr_matvecs or csc_matvecs\u001b[39;00m\n\u001b[0;32m    500\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matvecs\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# First, add the mapped labels to the DataFrame\n",
    "df_generate['mapped_label'] = df_generate['naics_code'].map(dictionar)\n",
    "df_generate = df_generate.dropna(subset=['mapped_label'])\n",
    "\n",
    "\n",
    "# Split the DataFrame into features (X) and labels (y)\n",
    "X = df_generate['name']  # Assuming 'name' column contains company names which will be used as features\n",
    "y = df_generate['mapped_label']  # The new column with mapped labels\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Choose whether to use BoW or TF-IDF, here we demonstrate both\n",
    "\n",
    "# Using BoW for feature extraction\n",
    "bow_vectorizer = CountVectorizer()\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "# Alternatively, using TF-IDF for feature extraction\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=1000)  # Increased max_iter in case the default isn't sufficient\n",
    "\n",
    "# Train the Logistic Regression model using BoW features\n",
    "log_reg.fit(X_train_bow, y_train)\n",
    "\n",
    "# Predict on the test data using BoW features\n",
    "y_pred_bow = log_reg.predict(X_test_bow)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy with BoW:\", accuracy_score(y_test, y_pred_bow))\n",
    "print(\"Classification Report with BoW:\")\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "\n",
    "# Train the Logistic Regression model using TF-IDF features\n",
    "log_reg.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test data using TF-IDF features\n",
    "y_pred_tfidf = log_reg.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy with TF-IDF:\", accuracy_score(y_test, y_pred_tfidf))\n",
    "print(\"Classification Report with TF-IDF:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BoW Features\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report\n",
    "\n",
    "# Initialize the vectorizers\n",
    "bow_vectorizer = CountVectorizer()\n",
    "\n",
    "# tfidf_vectorizer = TfidfVectorizer()\n",
    "# X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "# X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Transform the text data\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "# Define the parameter grid for 'C' and 'solver'\n",
    "param_grid = {\n",
    "    'C': [0.1, 1,10],\n",
    "    'solver': ['newton-cg', 'saga'],\n",
    "    'class_weight':['balanced']\n",
    "}\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "log_reg = LogisticRegression(max_iter=5000)\n",
    "\n",
    "# Initialize GridSearchCV with the logistic regression estimator and the parameter grid\n",
    "grid_search = GridSearchCV(log_reg, param_grid, cv=5, scoring=make_scorer(f1_score, average='macro'), verbose=1)\n",
    "\n",
    "# Train and evaluate using BoW features\n",
    "print(\"Evaluating BoW Features\")\n",
    "grid_search.fit(X_train_bow, y_train)\n",
    "print(\"Best parameters for BoW:\", grid_search.best_params_)\n",
    "y_pred_bow = grid_search.predict(X_test_bow)\n",
    "print(\"F1 Score with BoW:\", f1_score(y_test, y_pred_bow, average='macro'))\n",
    "print(\"Classification Report with BoW:\")\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "\n",
    "# # Train and evaluate using TF-IDF features\n",
    "# print(\"Evaluating TF-IDF Features\")\n",
    "# grid_search.fit(X_train_tfidf, y_train)\n",
    "# print(\"Best parameters for TF-IDF:\", grid_search.best_params_)\n",
    "# y_pred_tfidf_nb = grid_search.predict(X_test_tfidf)\n",
    "# print(\"F1 Score with TF-IDF:\", f1_score(y_test, y_pred_tfidf, average='macro'))\n",
    "# print(\"Classification Report with TF-IDF:\")\n",
    "# print(classification_report(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BoW Features\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for BoW: {'alpha': 0.1}\n",
      "F1 Score with BoW: 0.2329959309324207\n",
      "Classification Report with BoW:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.53      0.30      0.38       146\n",
      "         1.0       0.59      0.31      0.41       103\n",
      "         2.0       0.00      0.00      0.00         5\n",
      "         3.0       0.00      0.00      0.00         3\n",
      "         4.0       0.00      0.00      0.00         7\n",
      "         5.0       0.00      0.00      0.00        30\n",
      "         6.0       0.75      0.08      0.15        37\n",
      "         7.0       0.55      0.09      0.16        65\n",
      "         8.0       0.54      0.28      0.37       135\n",
      "         9.0       0.45      0.22      0.30       184\n",
      "        10.0       0.12      0.03      0.04        37\n",
      "        11.0       0.38      0.53      0.44       531\n",
      "        12.0       0.41      0.38      0.40       276\n",
      "        13.0       0.66      0.27      0.39       106\n",
      "        14.0       0.00      0.00      0.00         9\n",
      "        15.0       0.50      0.13      0.21        97\n",
      "        16.0       0.60      0.06      0.12        47\n",
      "        17.0       0.56      0.09      0.16        55\n",
      "        18.0       0.57      0.12      0.20        66\n",
      "        19.0       0.38      0.07      0.12        85\n",
      "        20.0       0.74      0.22      0.34        89\n",
      "        21.0       0.00      0.00      0.00        12\n",
      "        22.0       0.38      0.20      0.26       350\n",
      "        23.0       0.47      0.27      0.34       163\n",
      "        24.0       0.58      0.27      0.37       139\n",
      "        25.0       0.50      0.05      0.08        65\n",
      "        26.0       0.36      0.34      0.35       361\n",
      "        27.0       0.29      0.34      0.31       481\n",
      "        28.0       0.42      0.14      0.21       225\n",
      "        29.0       0.39      0.14      0.21       181\n",
      "        30.0       0.31      0.12      0.17       202\n",
      "        31.0       0.51      0.33      0.40       178\n",
      "        32.0       0.37      0.14      0.20       207\n",
      "        33.0       0.18      0.23      0.20       332\n",
      "        34.0       0.11      0.03      0.04        73\n",
      "        35.0       0.00      0.00      0.00         3\n",
      "        36.0       0.43      0.33      0.37       174\n",
      "        37.0       0.51      0.27      0.35       164\n",
      "        38.0       0.38      0.15      0.22       189\n",
      "        45.0       0.75      0.10      0.17        31\n",
      "        46.0       0.00      0.00      0.00         4\n",
      "        47.0       0.00      0.00      0.00         5\n",
      "        48.0       0.56      0.46      0.51       127\n",
      "        49.0       0.79      0.53      0.64       103\n",
      "        50.0       0.00      0.00      0.00         2\n",
      "        51.0       0.00      0.00      0.00         9\n",
      "        52.0       0.50      0.20      0.28       107\n",
      "        54.0       0.83      0.21      0.33        48\n",
      "        55.0       0.80      0.11      0.19        38\n",
      "        56.0       0.53      0.29      0.37       168\n",
      "        57.0       0.00      0.00      0.00         1\n",
      "        58.0       0.00      0.00      0.00         1\n",
      "        59.0       0.43      0.15      0.22        89\n",
      "        60.0       1.00      0.03      0.06        34\n",
      "        61.0       1.00      0.44      0.62         9\n",
      "        63.0       0.59      0.40      0.48       178\n",
      "        64.0       0.42      0.25      0.31       132\n",
      "        65.0       0.81      0.40      0.54       136\n",
      "        66.0       0.00      0.00      0.00         3\n",
      "        67.0       0.47      0.46      0.46       224\n",
      "        68.0       0.66      0.37      0.47       140\n",
      "        69.0       0.00      0.00      0.00         1\n",
      "        70.0       0.20      0.70      0.31      1033\n",
      "        72.0       0.39      0.43      0.41       505\n",
      "        73.0       0.74      0.48      0.58       146\n",
      "        74.0       0.47      0.45      0.46       361\n",
      "        75.0       0.47      0.62      0.54       473\n",
      "        76.0       0.00      0.00      0.00         5\n",
      "        77.0       0.38      0.08      0.13        62\n",
      "        78.0       0.29      0.17      0.22        98\n",
      "        79.0       0.41      0.19      0.26       127\n",
      "        80.0       0.56      0.12      0.20        42\n",
      "        81.0       0.38      0.19      0.25        96\n",
      "        82.0       0.57      0.36      0.44        69\n",
      "        83.0       0.41      0.32      0.36       179\n",
      "        84.0       0.43      0.48      0.45       322\n",
      "        85.0       0.49      0.40      0.44       182\n",
      "        86.0       0.37      0.35      0.36       291\n",
      "        87.0       0.00      0.00      0.00         2\n",
      "        88.0       0.00      0.00      0.00         5\n",
      "        89.0       0.00      0.00      0.00        10\n",
      "        92.0       0.00      0.00      0.00         3\n",
      "        95.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.35     11218\n",
      "   macro avg       0.38      0.20      0.23     11218\n",
      "weighted avg       0.42      0.35      0.34     11218\n",
      "\n",
      "Evaluating TF-IDF Features\n",
      "Fitting 5 folds for each of 3 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'alpha': 0.1}\n",
      "F1 Score with TF-IDF: 0.1914037224622481\n",
      "Classification Report with TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.54      0.24      0.33       146\n",
      "         1.0       0.61      0.18      0.28       103\n",
      "         2.0       0.00      0.00      0.00         5\n",
      "         3.0       0.00      0.00      0.00         3\n",
      "         4.0       0.00      0.00      0.00         7\n",
      "         5.0       0.00      0.00      0.00        30\n",
      "         6.0       1.00      0.05      0.10        37\n",
      "         7.0       0.67      0.09      0.16        65\n",
      "         8.0       0.59      0.18      0.27       135\n",
      "         9.0       0.48      0.16      0.24       184\n",
      "        10.0       0.00      0.00      0.00        37\n",
      "        11.0       0.35      0.57      0.43       531\n",
      "        12.0       0.42      0.37      0.39       276\n",
      "        13.0       0.73      0.21      0.32       106\n",
      "        14.0       0.00      0.00      0.00         9\n",
      "        15.0       0.52      0.11      0.19        97\n",
      "        16.0       0.67      0.04      0.08        47\n",
      "        17.0       0.50      0.02      0.04        55\n",
      "        18.0       0.50      0.03      0.06        66\n",
      "        19.0       0.20      0.01      0.02        85\n",
      "        20.0       0.70      0.16      0.26        89\n",
      "        21.0       0.00      0.00      0.00        12\n",
      "        22.0       0.42      0.18      0.26       350\n",
      "        23.0       0.52      0.23      0.32       163\n",
      "        24.0       0.60      0.15      0.24       139\n",
      "        25.0       0.67      0.03      0.06        65\n",
      "        26.0       0.39      0.33      0.36       361\n",
      "        27.0       0.28      0.38      0.32       481\n",
      "        28.0       0.51      0.11      0.18       225\n",
      "        29.0       0.40      0.09      0.15       181\n",
      "        30.0       0.33      0.10      0.15       202\n",
      "        31.0       0.54      0.31      0.39       178\n",
      "        32.0       0.42      0.10      0.16       207\n",
      "        33.0       0.17      0.21      0.19       332\n",
      "        34.0       0.12      0.01      0.02        73\n",
      "        35.0       0.00      0.00      0.00         3\n",
      "        36.0       0.44      0.28      0.34       174\n",
      "        37.0       0.58      0.24      0.34       164\n",
      "        38.0       0.44      0.13      0.20       189\n",
      "        45.0       0.50      0.03      0.06        31\n",
      "        46.0       0.00      0.00      0.00         4\n",
      "        47.0       0.00      0.00      0.00         5\n",
      "        48.0       0.57      0.39      0.47       127\n",
      "        49.0       0.83      0.37      0.51       103\n",
      "        50.0       0.00      0.00      0.00         2\n",
      "        51.0       0.00      0.00      0.00         9\n",
      "        52.0       0.61      0.13      0.22       107\n",
      "        54.0       0.86      0.12      0.22        48\n",
      "        55.0       0.67      0.05      0.10        38\n",
      "        56.0       0.63      0.22      0.33       168\n",
      "        57.0       0.00      0.00      0.00         1\n",
      "        58.0       0.00      0.00      0.00         1\n",
      "        59.0       0.46      0.12      0.19        89\n",
      "        60.0       0.00      0.00      0.00        34\n",
      "        61.0       0.00      0.00      0.00         9\n",
      "        63.0       0.70      0.33      0.44       178\n",
      "        64.0       0.45      0.19      0.27       132\n",
      "        65.0       0.83      0.29      0.43       136\n",
      "        66.0       0.00      0.00      0.00         3\n",
      "        67.0       0.49      0.40      0.44       224\n",
      "        68.0       0.80      0.26      0.40       140\n",
      "        69.0       0.00      0.00      0.00         1\n",
      "        70.0       0.19      0.77      0.30      1033\n",
      "        72.0       0.35      0.43      0.39       505\n",
      "        73.0       0.78      0.40      0.53       146\n",
      "        74.0       0.46      0.43      0.45       361\n",
      "        75.0       0.43      0.63      0.51       473\n",
      "        76.0       0.00      0.00      0.00         5\n",
      "        77.0       0.40      0.03      0.06        62\n",
      "        78.0       0.33      0.11      0.17        98\n",
      "        79.0       0.44      0.13      0.20       127\n",
      "        80.0       1.00      0.10      0.17        42\n",
      "        81.0       0.48      0.14      0.21        96\n",
      "        82.0       0.69      0.29      0.41        69\n",
      "        83.0       0.43      0.28      0.34       179\n",
      "        84.0       0.42      0.48      0.45       322\n",
      "        85.0       0.59      0.36      0.45       182\n",
      "        86.0       0.35      0.31      0.33       291\n",
      "        87.0       0.00      0.00      0.00         2\n",
      "        88.0       0.00      0.00      0.00         5\n",
      "        89.0       0.00      0.00      0.00        10\n",
      "        92.0       0.00      0.00      0.00         3\n",
      "        95.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.33     11218\n",
      "   macro avg       0.37      0.16      0.19     11218\n",
      "weighted avg       0.43      0.33      0.31     11218\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report\n",
    "\n",
    "# Initialize the vectorizers\n",
    "bow_vectorizer = CountVectorizer()\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transform the text data using BoW and TF-IDF\n",
    "X_train_bow = bow_vectorizer.fit_transform(X_train)\n",
    "X_test_bow = bow_vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for Naive Bayes 'alpha' (Laplace smoothing parameter)\n",
    "param_grid = {\n",
    "    'alpha': [0.1, 0.5, 1.0]\n",
    "}\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "# Initialize GridSearchCV with the Naive Bayes estimator and the parameter grid\n",
    "grid_search_nb = GridSearchCV(nb_clf, param_grid, cv=5, scoring=make_scorer(f1_score, average='macro'), verbose=1)\n",
    "\n",
    "# Train and evaluate using BoW features\n",
    "print(\"Evaluating BoW Features\")\n",
    "grid_search_nb.fit(X_train_bow, y_train)\n",
    "print(\"Best parameters for BoW:\", grid_search_nb.best_params_)\n",
    "y_pred_bow_nb = grid_search_nb.predict(X_test_bow)\n",
    "print(\"F1 Score with BoW:\", f1_score(y_test, y_pred_bow_nb, average='macro'))\n",
    "print(\"Classification Report with BoW:\")\n",
    "print(classification_report(y_test, y_pred_bow_nb))\n",
    "\n",
    "# Train and evaluate using TF-IDF features\n",
    "print(\"Evaluating TF-IDF Features\")\n",
    "grid_search_nb.fit(X_train_tfidf, y_train)\n",
    "print(\"Best parameters for TF-IDF:\", grid_search_nb.best_params_)\n",
    "y_pred_tfidf_nb = grid_search_nb.predict(X_test_tfidf)\n",
    "print(\"F1 Score with TF-IDF:\", f1_score(y_test, y_pred_tfidf_nb, average='macro'))\n",
    "print(\"Classification Report with TF-IDF:\")\n",
    "print(classification_report(y_test, y_pred_tfidf_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BoW Features\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for BoW: {'svm__C': 0.1, 'svm__class_weight': 'balanced', 'svm__kernel': 'linear'}\n",
      "F1 Score with BoW: 0.21681613323451565\n",
      "Classification Report with BoW:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.23      0.16      0.19       146\n",
      "         1.0       0.15      0.35      0.21       103\n",
      "         2.0       0.00      0.00      0.00         5\n",
      "         3.0       0.50      0.33      0.40         3\n",
      "         4.0       0.03      0.14      0.05         7\n",
      "         5.0       0.11      0.17      0.13        30\n",
      "         6.0       0.20      0.22      0.21        37\n",
      "         7.0       0.05      0.06      0.06        65\n",
      "         8.0       0.31      0.33      0.32       135\n",
      "         9.0       0.27      0.35      0.30       184\n",
      "        10.0       0.08      0.14      0.10        37\n",
      "        11.0       0.41      0.30      0.35       531\n",
      "        12.0       0.40      0.25      0.31       276\n",
      "        13.0       0.15      0.26      0.19       106\n",
      "        14.0       0.09      0.11      0.10         9\n",
      "        15.0       0.27      0.20      0.23        97\n",
      "        16.0       0.10      0.13      0.11        47\n",
      "        17.0       0.36      0.25      0.30        55\n",
      "        18.0       0.21      0.26      0.23        66\n",
      "        19.0       0.25      0.27      0.26        85\n",
      "        20.0       0.16      0.30      0.21        89\n",
      "        21.0       0.00      0.00      0.00        12\n",
      "        22.0       0.26      0.14      0.18       350\n",
      "        23.0       0.37      0.25      0.30       163\n",
      "        24.0       0.24      0.29      0.27       139\n",
      "        25.0       0.11      0.18      0.14        65\n",
      "        26.0       0.30      0.23      0.26       361\n",
      "        27.0       0.28      0.20      0.23       481\n",
      "        28.0       0.22      0.15      0.18       225\n",
      "        29.0       0.21      0.11      0.15       181\n",
      "        30.0       0.13      0.07      0.09       202\n",
      "        31.0       0.36      0.33      0.34       178\n",
      "        32.0       0.28      0.15      0.20       207\n",
      "        33.0       0.14      0.11      0.12       332\n",
      "        34.0       0.09      0.10      0.09        73\n",
      "        35.0       0.00      0.00      0.00         3\n",
      "        36.0       0.35      0.33      0.34       174\n",
      "        37.0       0.28      0.20      0.23       164\n",
      "        38.0       0.30      0.19      0.23       189\n",
      "        45.0       0.28      0.45      0.35        31\n",
      "        46.0       0.00      0.00      0.00         4\n",
      "        47.0       0.00      0.00      0.00         5\n",
      "        48.0       0.50      0.56      0.53       127\n",
      "        49.0       0.67      0.50      0.57       103\n",
      "        50.0       0.00      0.00      0.00         2\n",
      "        51.0       0.12      0.11      0.12         9\n",
      "        52.0       0.29      0.21      0.24       107\n",
      "        54.0       0.56      0.29      0.38        48\n",
      "        55.0       0.12      0.13      0.12        38\n",
      "        56.0       0.43      0.31      0.36       168\n",
      "        57.0       0.00      0.00      0.00         1\n",
      "        58.0       0.00      0.00      0.00         1\n",
      "        59.0       0.17      0.16      0.16        89\n",
      "        60.0       0.38      0.09      0.14        34\n",
      "        61.0       0.60      0.67      0.63         9\n",
      "        63.0       0.57      0.41      0.48       178\n",
      "        64.0       0.30      0.30      0.30       132\n",
      "        65.0       0.47      0.46      0.47       136\n",
      "        66.0       0.00      0.00      0.00         3\n",
      "        67.0       0.43      0.33      0.37       224\n",
      "        68.0       0.42      0.43      0.42       140\n",
      "        69.0       0.00      0.00      0.00         1\n",
      "        70.0       0.16      0.44      0.23      1033\n",
      "        72.0       0.43      0.26      0.32       505\n",
      "        73.0       0.50      0.45      0.47       146\n",
      "        74.0       0.38      0.26      0.31       361\n",
      "        75.0       0.60      0.44      0.51       473\n",
      "        76.0       0.00      0.00      0.00         5\n",
      "        77.0       0.15      0.08      0.11        62\n",
      "        78.0       0.22      0.14      0.17        98\n",
      "        79.0       0.26      0.27      0.27       127\n",
      "        80.0       0.26      0.29      0.27        42\n",
      "        81.0       0.27      0.17      0.21        96\n",
      "        82.0       0.32      0.42      0.36        69\n",
      "        83.0       0.43      0.21      0.28       179\n",
      "        84.0       0.56      0.30      0.39       322\n",
      "        85.0       0.42      0.32      0.36       182\n",
      "        86.0       0.41      0.18      0.25       291\n",
      "        87.0       0.00      0.00      0.00         2\n",
      "        88.0       0.00      0.00      0.00         5\n",
      "        89.0       0.33      0.20      0.25        10\n",
      "        92.0       0.00      0.00      0.00         3\n",
      "        95.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.27     11218\n",
      "   macro avg       0.24      0.21      0.22     11218\n",
      "weighted avg       0.32      0.27      0.28     11218\n",
      "\n",
      "Evaluating TF-IDF Features\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\svm\\_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=5000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters for TF-IDF: {'svm__C': 0.1, 'svm__class_weight': 'balanced', 'svm__kernel': 'linear'}\n",
      "F1 Score with TF-IDF: 0.22056949404922813\n",
      "Classification Report with TF-IDF:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.28      0.20      0.23       146\n",
      "         1.0       0.02      0.47      0.03       103\n",
      "         2.0       0.00      0.00      0.00         5\n",
      "         3.0       0.50      0.33      0.40         3\n",
      "         4.0       0.06      0.14      0.08         7\n",
      "         5.0       0.14      0.20      0.16        30\n",
      "         6.0       0.28      0.30      0.29        37\n",
      "         7.0       0.19      0.12      0.15        65\n",
      "         8.0       0.33      0.30      0.31       135\n",
      "         9.0       0.26      0.36      0.30       184\n",
      "        10.0       0.08      0.14      0.10        37\n",
      "        11.0       0.43      0.33      0.37       531\n",
      "        12.0       0.40      0.28      0.33       276\n",
      "        13.0       0.27      0.33      0.29       106\n",
      "        14.0       0.09      0.11      0.10         9\n",
      "        15.0       0.31      0.22      0.26        97\n",
      "        16.0       0.13      0.15      0.14        47\n",
      "        17.0       0.33      0.22      0.26        55\n",
      "        18.0       0.24      0.32      0.27        66\n",
      "        19.0       0.27      0.29      0.28        85\n",
      "        20.0       0.29      0.33      0.31        89\n",
      "        21.0       0.00      0.00      0.00        12\n",
      "        22.0       0.29      0.16      0.20       350\n",
      "        23.0       0.37      0.26      0.31       163\n",
      "        24.0       0.29      0.27      0.28       139\n",
      "        25.0       0.13      0.17      0.15        65\n",
      "        26.0       0.34      0.26      0.30       361\n",
      "        27.0       0.29      0.22      0.25       481\n",
      "        28.0       0.23      0.16      0.19       225\n",
      "        29.0       0.20      0.11      0.14       181\n",
      "        30.0       0.12      0.07      0.09       202\n",
      "        31.0       0.37      0.31      0.34       178\n",
      "        32.0       0.28      0.17      0.21       207\n",
      "        33.0       0.14      0.10      0.12       332\n",
      "        34.0       0.10      0.11      0.11        73\n",
      "        35.0       0.00      0.00      0.00         3\n",
      "        36.0       0.33      0.32      0.32       174\n",
      "        37.0       0.29      0.20      0.24       164\n",
      "        38.0       0.26      0.17      0.21       189\n",
      "        45.0       0.26      0.42      0.32        31\n",
      "        46.0       0.00      0.00      0.00         4\n",
      "        47.0       0.00      0.00      0.00         5\n",
      "        48.0       0.47      0.55      0.51       127\n",
      "        49.0       0.65      0.54      0.59       103\n",
      "        50.0       0.00      0.00      0.00         2\n",
      "        51.0       0.00      0.00      0.00         9\n",
      "        52.0       0.32      0.22      0.26       107\n",
      "        53.0       0.00      0.00      0.00         0\n",
      "        54.0       0.52      0.27      0.36        48\n",
      "        55.0       0.11      0.13      0.12        38\n",
      "        56.0       0.45      0.33      0.38       168\n",
      "        57.0       0.00      0.00      0.00         1\n",
      "        58.0       0.00      0.00      0.00         1\n",
      "        59.0       0.18      0.18      0.18        89\n",
      "        60.0       0.42      0.15      0.22        34\n",
      "        61.0       0.67      0.67      0.67         9\n",
      "        63.0       0.54      0.43      0.48       178\n",
      "        64.0       0.31      0.24      0.27       132\n",
      "        65.0       0.50      0.47      0.48       136\n",
      "        66.0       0.00      0.00      0.00         3\n",
      "        67.0       0.43      0.36      0.39       224\n",
      "        68.0       0.48      0.43      0.45       140\n",
      "        69.0       0.00      0.00      0.00         1\n",
      "        70.0       0.39      0.21      0.27      1033\n",
      "        72.0       0.43      0.28      0.34       505\n",
      "        73.0       0.51      0.51      0.51       146\n",
      "        74.0       0.39      0.30      0.34       361\n",
      "        75.0       0.58      0.44      0.50       473\n",
      "        76.0       0.00      0.00      0.00         5\n",
      "        77.0       0.21      0.13      0.16        62\n",
      "        78.0       0.25      0.19      0.22        98\n",
      "        79.0       0.26      0.27      0.26       127\n",
      "        80.0       0.31      0.33      0.32        42\n",
      "        81.0       0.29      0.21      0.24        96\n",
      "        82.0       0.35      0.43      0.39        69\n",
      "        83.0       0.42      0.22      0.29       179\n",
      "        84.0       0.55      0.33      0.41       322\n",
      "        85.0       0.46      0.35      0.40       182\n",
      "        86.0       0.41      0.23      0.29       291\n",
      "        87.0       0.00      0.00      0.00         2\n",
      "        88.0       0.00      0.00      0.00         5\n",
      "        89.0       0.25      0.20      0.22        10\n",
      "        90.0       0.00      0.00      0.00         0\n",
      "        92.0       0.00      0.00      0.00         3\n",
      "        93.0       0.00      0.00      0.00         0\n",
      "        95.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.27     11218\n",
      "   macro avg       0.25      0.21      0.22     11218\n",
      "weighted avg       0.35      0.27      0.30     11218\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report\n",
    "\n",
    "# Define the pipeline with StandardScaler and SVC\n",
    "pipe_bow = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),  # Use with_mean=False to return a sparse matrix\n",
    "    ('svm', SVC(max_iter=5000))\n",
    "])\n",
    "\n",
    "pipe_tfidf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),  # Use with_mean=False to return a sparse matrix\n",
    "    ('svm', SVC(max_iter=5000))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for SVM\n",
    "param_grid = {\n",
    "    'svm__C': [0.1, 1, 10],  # Regularization parameter\n",
    "    'svm__kernel': ['linear', 'rbf'],  # Type of SVM kernel to use\n",
    "    'svm__class_weight': ['balanced']  # Automatically adjust weights inversely proportional to class frequencies\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the pipeline and the parameter grid\n",
    "grid_search_bow = GridSearchCV(pipe_bow, param_grid, cv=5, scoring=make_scorer(f1_score, average='macro'), verbose=1)\n",
    "grid_search_tfidf = GridSearchCV(pipe_tfidf, param_grid, cv=5, scoring=make_scorer(f1_score, average='macro'), verbose=1)\n",
    "\n",
    "# Train and evaluate using BoW features\n",
    "print(\"Evaluating BoW Features\")\n",
    "grid_search_bow.fit(X_train, y_train)\n",
    "print(\"Best parameters for BoW:\", grid_search_bow.best_params_)\n",
    "y_pred_bow = grid_search_bow.predict(X_test)\n",
    "print(\"F1 Score with BoW:\", f1_score(y_test, y_pred_bow, average='macro'))\n",
    "print(\"Classification Report with BoW:\")\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "\n",
    "# Train and evaluate using TF-IDF features\n",
    "print(\"Evaluating TF-IDF Features\")\n",
    "grid_search_tfidf.fit(X_train, y_train)\n",
    "print(\"Best parameters for TF-IDF:\", grid_search_tfidf.best_params_)\n",
    "y_pred_tfidf = grid_search_tfidf.predict(X_test)\n",
    "print(\"F1 Score with TF-IDF:\", f1_score(y_test, y_pred_tfidf, average='macro'))\n",
    "print(\"Classification Report with TF-IDF:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating BoW Features\n",
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wadu\\anaconda3\\envs\\pachet\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Define the pipeline with CountVectorizer and RandomForest\n",
    "pipe_bow = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),  # Use with_mean=False to maintain sparsity\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "pipe_tfidf = Pipeline([\n",
    "    ('vectorizer', TfidfVectorizer()),\n",
    "    ('scaler', StandardScaler(with_mean=False)),  # Use with_mean=False to maintain sparsity\n",
    "    ('rf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'rf__n_estimators': [100, 200],  # Number of trees in the forest\n",
    "    'rf__max_depth': [None, 10],  # Maximum depth of the tree\n",
    "\n",
    "    'rf__class_weight': ['balanced']  # Weights associated with classes\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the pipeline and the parameter grid\n",
    "grid_search_bow = GridSearchCV(pipe_bow, param_grid, cv=5, scoring=make_scorer(f1_score, average='macro'), verbose=1)\n",
    "grid_search_tfidf = GridSearchCV(pipe_tfidf, param_grid, cv=5, scoring=make_scorer(f1_score, average='macro'), verbose=1)\n",
    "\n",
    "# Train and evaluate using BoW features\n",
    "print(\"Evaluating BoW Features\")\n",
    "grid_search_bow.fit(X_train, y_train)\n",
    "print(\"Best parameters for BoW:\", grid_search_bow.best_params_)\n",
    "y_pred_bow = grid_search_bow.predict(X_test)\n",
    "print(\"F1 Score with BoW:\", f1_score(y_test, y_pred_bow, average='macro'))\n",
    "print(\"Classification Report with BoW:\")\n",
    "print(classification_report(y_test, y_pred_bow))\n",
    "\n",
    "# Train and evaluate using TF-IDF features\n",
    "print(\"Evaluating TF-IDF Features\")\n",
    "grid_search_tfidf.fit(X_train, y_train)\n",
    "print(\"Best parameters for TF-IDF:\", grid_search_tfidf.best_params_)\n",
    "y_pred_tfidf = grid_search_tfidf.predict(X_test)\n",
    "print(\"F1 Score with TF-IDF:\", f1_score(y_test, y_pred_tfidf, average='macro'))\n",
    "print(\"Classification Report with TF-IDF:\")\n",
    "print(classification_report(y_test, y_pred_tfidf))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pachet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
